{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "import pkg_resources\n",
    "from string import punctuation\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "mistakes = []\n",
    "all_suggestions = []\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "dictionary_path = \"C://Users//tonch//AppData//Local//Programs//Python//Python39-32//Lib//site-packages//symspellpy//frequency_dictionary_en_82_765.txt\"\n",
    "bigram_dictionary = \"C://Users//tonch//AppData//Local//Programs//Python//Python39-32//Lib//site-packages//symspellpy//frequency_bigramdictionary_en_243_342.txt\"\n",
    "sym_spell.load_dictionary(dictionary_path, 0, 1)\n",
    "sym_spell.load_bigram_dictionary(dictionary_path, 0, 2)\n",
    "incorrect_file = open(\n",
    "    \"C://Users//tonch//AppData//Local//Programs//Python//Python39-32//Lib//site-packages//symspellpy//FuckedUp.txt\",\n",
    "    encoding=\"utf-8\").readlines()\n",
    "correct_file = open(\n",
    "    \"C://Users//tonch//AppData//Local//Programs//Python//Python39-32//Lib//site-packages//symspellpy//Correct.txt\",\n",
    "    encoding=\"utf-8\").readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mistaken(word, dictionary):\n",
    "    words = dictionary.keys()\n",
    "    if word in words:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['unknowingly', 'unknowingly'], ['short', 'short'], ['tow', 'two'], ['change', 'change'], ['you', 'you'], ['bitter', 'butter'], ['name', 'name'], ['probably', 'probably'], ['being', 'being'], ['masterpiece', 'masterpiece'], ['dharma', 'Charisma'], ['rad', 'red'], ['tres', 'trees.'], ['random', 'random'], ['eating', 'eating'], ['weight', 'weight'], ['literary', 'literally'], ['choose', 'chose'], ['lemonade', 'lemonade.'], ['laser', 'easier'], ['always', 'always'], ['are', 'care'], ['persons', 'persons'], ['underneath', 'underneath'], ['panel', 'piano.'], ['barbecue', 'barbecue'], ['from', 'from'], ['it', 'not'], ['vines', 'vines'], ['clan', 'clean'], ['bring', 'brain'], ['from', 'farm.'], ['candid', 'candied'], ['watermelon', 'watermelon.'], ['use', 'house.'], ['pings', 'pilings'], ['part', 'ear'], ['people', 'people'], ['certain', 'certain'], ['baggage', 'baggage.'], ['power', 'shower'], ['very', 'Becky'], ['prev', 'prove'], ['floor', 'floor'], ['still', 'still'], ['the', 'the'], ['bach', 'beach,'], ['most', 'most'], ['new', 'news.']]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.78      0.14        49\n",
      "           1       0.91      0.20      0.33       568\n",
      "\n",
      "    accuracy                           0.24       617\n",
      "   macro avg       0.49      0.49      0.23       617\n",
      "weighted avg       0.85      0.24      0.31       617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "line = 0\n",
    "for sentence in incorrect_file:\n",
    "    word_num = 0\n",
    "    correct_line = correct_file[line].split()\n",
    "\n",
    "    for word in sentence.split():\n",
    "        pair = []\n",
    "        pair.append(sorted(sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=2), key=lambda x: x.count, reverse=True)[0].term)\n",
    "        pair.append(correct_line[word_num])\n",
    "        if word.strip(punctuation) != correct_line[word_num].strip(punctuation):\n",
    "            y_true.append(0)\n",
    "            mistakes.append(pair)\n",
    "        else:\n",
    "            y_true.append(1)\n",
    "        y_pred.append(predict_mistaken(pair[1], sym_spell.words))\n",
    "        word_num += 1\n",
    "    line += 1\n",
    "print(mistakes)\n",
    "print(classification_report(y_true, y_pred, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Report: (sentences, lookup_compound)\n",
    "#            0       0.03      0.54      0.06        28\n",
    "#            1       0.90      0.19      0.31       589\n",
    "#\n",
    "#     accuracy                           0.20       617\n",
    "#    macro avg       0.46      0.36      0.18       617\n",
    "# weighted avg       0.86      0.20      0.30       617\n",
    "#\n",
    "# Classification Report: (word)\n",
    "#            0       0.08      0.78      0.14        49\n",
    "#            1       0.91      0.20      0.33       568\n",
    "#\n",
    "#     accuracy                           0.24       617\n",
    "#    macro avg       0.49      0.49      0.23       617\n",
    "# weighted avg       0.85      0.24      0.31       617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['unknowingly', 'unknowingly'], ['short', 'short'], ['tow', 'two'], ['change', 'change'], ['you', 'you'], ['bitter', 'butter'], ['name', 'name'], ['probably', 'probably'], ['being', 'being'], ['masterpiece', 'masterpiece'], ['dharma', 'Charisma'], ['rad', 'red'], ['tres', 'trees.'], ['random', 'random'], ['eating', 'eating'], ['weight', 'weight'], ['literary', 'literally'], ['choose', 'chose'], ['lemonade', 'lemonade.'], ['laser', 'easier'], ['always', 'always'], ['are', 'care'], ['persons', 'persons'], ['underneath', 'underneath'], ['panel', 'piano.'], ['barbecue', 'barbecue'], ['from', 'from'], ['it', 'not'], ['vines', 'vines'], ['clan', 'clean'], ['bring', 'brain'], ['from', 'farm.'], ['candid', 'candied'], ['watermelon', 'watermelon.'], ['use', 'house.'], ['pings', 'pilings'], ['part', 'ear'], ['people', 'people'], ['certain', 'certain'], ['baggage', 'baggage.'], ['power', 'shower'], ['very', 'Becky'], ['prev', 'prove'], ['floor', 'floor'], ['still', 'still'], ['the', 'the'], ['bach', 'beach,'], ['most', 'most'], ['new', 'news.'], ['he had unknowingly', 'unknowingly'], ['for a short', 'short'], ['one or tow', 'two'], ['action would change', 'change'], ['nice until you', 'you'], ['put peanut bitter', 'butter'], ['out her name', 'name'], ['potato wedges probably', 'probably'], ['gift of being', 'being'], ['at the masterpiece', 'masterpiece'], ['points in charisma', 'Charisma'], ['in the rad', 'red'], ['of the tres', 'trees.'], ['of other random', 'random'], ['he loved eating', 'eating'], ['meets causes weight', 'weight'], ['when he literary', 'literally'], ['the artist choose', 'chose'], ['showers in lemonade', 'lemonade.'], ['dynamite were laser', 'easier'], ['he had always', 'always'], ['i didst are', 'care'], ['ruin a persons', 'persons'], ['hidden stash underneath', 'underneath'], ['plays the pan', 'piano.'], ['enjoyed the barbecue', 'barbecue'], ['proudly graduated from', 'from'], ['lights but it', 'not'], ['and intertwined vines', 'vines'], ['they are clan', 'clean'], ['turns your bring', 'brain'], ['sweet potato from', 'farm.'], ['transplanting seedlings candid', 'candied'], ['on the watermelon', 'watermelon.'], ['of the use', 'house.'], ['broke the pings', 'pilings'], ['into the part', 'ear'], ['about the people', 'people'], ['there are certain', 'certain'], ['with your baggage', 'baggage.'], ['but my power', 'shower'], ['toward earth becky', 'Becky'], ['peach to prev', 'prove'], ['often one floor', 'floor'], ['alligator brian still', 'still'], ['river stole the', 'the'], ['on the bach', 'beach,'], ['was the most', 'most'], ['delivered the new', 'news.']]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.78      0.14        49\n",
      "           1       0.91      0.20      0.33       568\n",
      "\n",
      "    accuracy                           0.24       617\n",
      "   macro avg       0.49      0.49      0.23       617\n",
      "weighted avg       0.85      0.24      0.31       617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "line = 0\n",
    "for sentence in incorrect_file:\n",
    "    word_num = 0\n",
    "    correct_line = correct_file[line].split()\n",
    "\n",
    "    for word in sentence.split():\n",
    "        trigram_og = \"\"\n",
    "        trigram_correct = \"\"\n",
    "        if word_num == 0:\n",
    "            trigram_og = word\n",
    "            trigram_correct = correct_line[0]\n",
    "        elif word_num == 1:\n",
    "            trigram_og = sentence.split()[0]+ \" \" + sentence.split()[1]\n",
    "            trigram_correct = correct_line[0] + \" \" + correct_line[1]\n",
    "        else:\n",
    "            trigram_og = sentence.split()[word_num - 2]+ \" \" + sentence.split()[word_num - 1] + \" \" + sentence.split()[word_num]\n",
    "            trigram_correct = correct_line[word_num - 2] + \" \" + correct_line[word_num - 1] + \" \" + correct_line[word_num]\n",
    "        pair = []\n",
    "        pair.append(sym_spell.lookup_compound(trigram_og, max_edit_distance=2)[0].term)\n",
    "        pair.append(correct_line[word_num])\n",
    "        if word.strip(punctuation) != correct_line[word_num].strip(punctuation):\n",
    "            y_true.append(0)\n",
    "            mistakes.append(pair)\n",
    "        else:\n",
    "            y_true.append(1)\n",
    "        y_pred.append(predict_mistaken(pair[1], sym_spell.words))\n",
    "        word_num += 1\n",
    "    line += 1\n",
    "print(mistakes)\n",
    "print(classification_report(y_true, y_pred, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Исходя из полученных данных, мы можем прийти к заключеию, что использование триграммной модели не имеет преимуществ \n",
    "#по сравнению с униграммной моделью.\n",
    "#Также, было проведено исследование с полным предложением. Использование полного предложения имеет преимущество над \n",
    "#униграммной и триграммной моделью"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
